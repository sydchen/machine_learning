{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd30e93",
   "metadata": {
    "id": "OYlaRwNu7ojq",
    "papermill": {
     "duration": 0.007676,
     "end_time": "2024-09-10T01:26:11.828327",
     "exception": false,
     "start_time": "2024-09-10T01:26:11.820651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Homework 2 Phoneme Classification**\n",
    "\n",
    "* Slides: https://docs.google.com/presentation/d/1v6HkBWiJb8WNDcJ9_-2kwVstxUWml87b9CnA16Gdoio/edit?usp=sharing\n",
    "* Kaggle: https://www.kaggle.com/c/ml2022spring-hw2\n",
    "* Video: TBA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae94c92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:26:11.843793Z",
     "iopub.status.busy": "2024-09-10T01:26:11.843472Z",
     "iopub.status.idle": "2024-09-10T01:26:12.903058Z",
     "shell.execute_reply": "2024-09-10T01:26:12.901949Z"
    },
    "id": "mLQI0mNcmM-O",
    "outputId": "7d5b4d81-9438-4d50-8153-cd235c47ee21",
    "papermill": {
     "duration": 1.070145,
     "end_time": "2024-09-10T01:26:12.905388",
     "exception": false,
     "start_time": "2024-09-10T01:26:11.835243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 10 01:26:12 2024       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   39C    P0             27W /  250W |       0MiB /  16384MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d4c020",
   "metadata": {
    "id": "KVUGfWTo7_Oj",
    "papermill": {
     "duration": 0.007502,
     "end_time": "2024-09-10T01:26:12.920221",
     "exception": false,
     "start_time": "2024-09-10T01:26:12.912719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Download Data\n",
    "Download data from google drive, then unzip it.\n",
    "\n",
    "You should have\n",
    "- `libriphone/train_split.txt`\n",
    "- `libriphone/train_labels`\n",
    "- `libriphone/test_split.txt`\n",
    "- `libriphone/feat/train/*.pt`: training feature<br>\n",
    "- `libriphone/feat/test/*.pt`:  testing feature<br>\n",
    "\n",
    "after running the following block.\n",
    "\n",
    "> **Notes: if the links are dead, you can download the data directly from [Kaggle](https://www.kaggle.com/c/ml2022spring-hw2/data) and upload it to the workspace, or you can use [the Kaggle API](https://www.kaggle.com/general/74235) to directly download the data into colab.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e035f9f5",
   "metadata": {
    "id": "Bj5jYXsD9Ef3",
    "papermill": {
     "duration": 0.006903,
     "end_time": "2024-09-10T01:26:12.934261",
     "exception": false,
     "start_time": "2024-09-10T01:26:12.927358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Download train/test metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a608e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:26:12.950092Z",
     "iopub.status.busy": "2024-09-10T01:26:12.949748Z",
     "iopub.status.idle": "2024-09-10T01:26:12.954439Z",
     "shell.execute_reply": "2024-09-10T01:26:12.953577Z"
    },
    "id": "OzkiMEcC3Foq",
    "outputId": "cc90c16c-ee21-400e-ec08-dfcd422212a6",
    "papermill": {
     "duration": 0.015052,
     "end_time": "2024-09-10T01:26:12.956452",
     "exception": false,
     "start_time": "2024-09-10T01:26:12.941400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main link\n",
    "#!wget -O libriphone.zip \"https://github.com/xraychen/shiny-robot/releases/download/v1.0/libriphone.zip\"\n",
    "\n",
    "# Backup Link 0\n",
    "# !pip install --upgrade gdown\n",
    "# !gdown --id '1o6Ag-G3qItSmYhTheX6DYiuyNzWyHyTc' --output libriphone.zip\n",
    "\n",
    "# Backup link 1\n",
    "# !pip install --upgrade gdown\n",
    "# !gdown --id '1R1uQYi4QpX0tBfUWt2mbZcncdBsJkxeW' --output libriphone.zip\n",
    "\n",
    "# Backup link 2\n",
    "# !wget -O libriphone.zip \"https://www.dropbox.com/s/wqww8c5dbrl2ka9/libriphone.zip?dl=1\"\n",
    "\n",
    "# Backup link 3\n",
    "# !wget -O libriphone.zip \"https://www.dropbox.com/s/p2ljbtb2bam13in/libriphone.zip?dl=1\"\n",
    "\n",
    "#!unzip \"/kaggle/input/libriphone/libriphone.zip\" -d /kaggle/input/libriphone/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d45206d",
   "metadata": {
    "id": "_L_4anls8Drv",
    "papermill": {
     "duration": 0.006881,
     "end_time": "2024-09-10T01:26:12.970343",
     "exception": false,
     "start_time": "2024-09-10T01:26:12.963462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86fc944",
   "metadata": {
    "id": "po4N3C-AWuWl",
    "papermill": {
     "duration": 0.006975,
     "end_time": "2024-09-10T01:26:12.984498",
     "exception": false,
     "start_time": "2024-09-10T01:26:12.977523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
    "\n",
    "A phoneme may span several frames and is dependent to past and future frames. \\\n",
    "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
    "\n",
    "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a49f8621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:26:13.000925Z",
     "iopub.status.busy": "2024-09-10T01:26:13.000553Z",
     "iopub.status.idle": "2024-09-10T01:26:17.119405Z",
     "shell.execute_reply": "2024-09-10T01:26:17.118622Z"
    },
    "id": "IJjLT8em-y9G",
    "papermill": {
     "duration": 4.129948,
     "end_time": "2024-09-10T01:26:17.121623",
     "exception": false,
     "start_time": "2024-09-10T01:26:12.991675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_feat(path):\n",
    "    feat = torch.load(path)\n",
    "    return feat\n",
    "\n",
    "def shift(x, n):\n",
    "    if n < 0:\n",
    "        left = x[0].repeat(-n, 1)\n",
    "        right = x[:n]\n",
    "\n",
    "    elif n > 0:\n",
    "        right = x[-1].repeat(n, 1)\n",
    "        left = x[n:]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    return torch.cat((left, right), dim=0)\n",
    "\n",
    "def concat_feat(x, concat_n):\n",
    "    assert concat_n % 2 == 1 # n must be odd\n",
    "    if concat_n < 2:\n",
    "        return x\n",
    "    seq_len, feature_dim = x.size(0), x.size(1)\n",
    "    x = x.repeat(1, concat_n) \n",
    "    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n",
    "    mid = (concat_n // 2)\n",
    "    for r_idx in range(1, mid+1):\n",
    "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
    "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
    "\n",
    "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
    "\n",
    "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, train_val_seed=1337):\n",
    "    class_num = 41 # NOTE: pre-computed, should not need change\n",
    "    mode = 'train' if (split == 'train' or split == 'val') else 'test'\n",
    "\n",
    "    label_dict = {}\n",
    "    if mode != 'test':\n",
    "      phone_file = open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines()\n",
    "\n",
    "      for line in phone_file:\n",
    "          line = line.strip('\\n').split(' ')\n",
    "          label_dict[line[0]] = [int(p) for p in line[1:]]\n",
    "\n",
    "    if split == 'train' or split == 'val':\n",
    "        # split training and validation data\n",
    "        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
    "        random.seed(train_val_seed)\n",
    "        random.shuffle(usage_list)\n",
    "        percent = int(len(usage_list) * train_ratio)\n",
    "        usage_list = usage_list[:percent] if split == 'train' else usage_list[percent:]\n",
    "    elif split == 'test':\n",
    "        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
    "    else:\n",
    "        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
    "\n",
    "    usage_list = [line.strip('\\n') for line in usage_list]\n",
    "    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
    "\n",
    "    max_len = 3000000\n",
    "    X = torch.empty(max_len, 39 * concat_nframes)\n",
    "    if mode != 'test':\n",
    "      y = torch.empty(max_len, dtype=torch.long)\n",
    "\n",
    "    idx = 0\n",
    "    for i, fname in tqdm(enumerate(usage_list)):\n",
    "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))            \n",
    "        cur_len = len(feat)\n",
    "        feat = concat_feat(feat, concat_nframes)\n",
    "        if mode != 'test':\n",
    "          label = torch.LongTensor(label_dict[fname])\n",
    "\n",
    "        X[idx: idx + cur_len, :] = feat\n",
    "        if mode != 'test':\n",
    "          y[idx: idx + cur_len] = label\n",
    "\n",
    "        idx += cur_len\n",
    "\n",
    "    X = X[:idx, :]\n",
    "    if mode != 'test':\n",
    "      y = y[:idx]\n",
    "\n",
    "    print(f'[INFO] {split} set')\n",
    "    print(X.shape)\n",
    "    if mode != 'test':\n",
    "      print(y.shape)\n",
    "      return X, y\n",
    "    else:\n",
    "      return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275151ce",
   "metadata": {
    "id": "us5XW_x6udZQ",
    "papermill": {
     "duration": 0.007039,
     "end_time": "2024-09-10T01:26:17.136496",
     "exception": false,
     "start_time": "2024-09-10T01:26:17.129457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e8f7b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:26:17.152541Z",
     "iopub.status.busy": "2024-09-10T01:26:17.152090Z",
     "iopub.status.idle": "2024-09-10T01:26:17.158823Z",
     "shell.execute_reply": "2024-09-10T01:26:17.157965Z"
    },
    "id": "Fjf5EcmJtf4e",
    "papermill": {
     "duration": 0.016908,
     "end_time": "2024-09-10T01:26:17.160725",
     "exception": false,
     "start_time": "2024-09-10T01:26:17.143817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class LibriDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.data = X\n",
    "        if y is not None:\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7451cd53",
   "metadata": {
    "id": "IRqKNvNZwe3V",
    "papermill": {
     "duration": 0.007253,
     "end_time": "2024-09-10T01:26:17.175271",
     "exception": false,
     "start_time": "2024-09-10T01:26:17.168018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5ce0ba1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:26:17.190658Z",
     "iopub.status.busy": "2024-09-10T01:26:17.190378Z",
     "iopub.status.idle": "2024-09-10T01:26:17.199308Z",
     "shell.execute_reply": "2024-09-10T01:26:17.198494Z"
    },
    "id": "Bg-GRd7ywdrL",
    "papermill": {
     "duration": 0.018845,
     "end_time": "2024-09-10T01:26:17.201245",
     "exception": false,
     "start_time": "2024-09-10T01:26:17.182400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=0.275)\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim, eps=1e-5, momentum=0.1, affine=True),\n",
    "            nn.ReLU(),               \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            BasicBlock(input_dim, hidden_dim),\n",
    "            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a98b1c",
   "metadata": {
    "id": "TlIq8JeqvvHC",
    "papermill": {
     "duration": 0.00722,
     "end_time": "2024-09-10T01:26:17.215848",
     "exception": false,
     "start_time": "2024-09-10T01:26:17.208628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c076598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:26:17.231708Z",
     "iopub.status.busy": "2024-09-10T01:26:17.231409Z",
     "iopub.status.idle": "2024-09-10T01:26:17.236443Z",
     "shell.execute_reply": "2024-09-10T01:26:17.235753Z"
    },
    "id": "iIHn79Iav1ri",
    "papermill": {
     "duration": 0.015439,
     "end_time": "2024-09-10T01:26:17.238491",
     "exception": false,
     "start_time": "2024-09-10T01:26:17.223052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data prarameters\n",
    "concat_nframes = 15              # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
    "train_ratio = 0.95               # the ratio of data used for training, the rest will be used for validation\n",
    "\n",
    "# training parameters\n",
    "seed = 220012                     # random seed\n",
    "batch_size = 512                # batch size\n",
    "num_epoch = 30                   # the number of training epoch\n",
    "learning_rate = 2e-4          # learning rate\n",
    "model_path = './model.ckpt'     # the path where the checkpoint will be saved\n",
    "\n",
    "# model parameters\n",
    "input_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\n",
    "hidden_layers = 3               # the number of hidden layers\n",
    "hidden_dim = 1400                # the hidden dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f70c8",
   "metadata": {
    "id": "IIUFRgG5yoDn",
    "papermill": {
     "duration": 0.007071,
     "end_time": "2024-09-10T01:26:17.252786",
     "exception": false,
     "start_time": "2024-09-10T01:26:17.245715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8609fc47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:26:17.268532Z",
     "iopub.status.busy": "2024-09-10T01:26:17.268228Z",
     "iopub.status.idle": "2024-09-10T01:27:06.210275Z",
     "shell.execute_reply": "2024-09-10T01:27:06.209184Z"
    },
    "id": "c1zI3v5jyrDn",
    "outputId": "3ea2823a-83f3-42d9-ef05-2f2c002f9538",
    "papermill": {
     "duration": 48.952582,
     "end_time": "2024-09-10T01:27:06.212618",
     "exception": false,
     "start_time": "2024-09-10T01:26:17.260036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] - # phone classes: 41, number of utterances for train: 4071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_23/2993276178.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  feat = torch.load(path)\n",
      "4071it [00:45, 89.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train set\n",
      "torch.Size([2513163, 585])\n",
      "torch.Size([2513163])\n",
      "[Dataset] - # phone classes: 41, number of utterances for val: 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "215it [00:02, 89.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val set\n",
      "torch.Size([130995, 585])\n",
      "torch.Size([130995])\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# preprocess data\n",
    "train_X, train_y = preprocess_data(split='train', feat_dir='/kaggle/input/libriphone/libriphone/feat', phone_path='/kaggle/input/libriphone/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
    "val_X, val_y = preprocess_data(split='val', feat_dir='/kaggle/input/libriphone/libriphone/feat', phone_path='/kaggle/input/libriphone/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
    "\n",
    "# get dataset\n",
    "train_set = LibriDataset(train_X, train_y)\n",
    "val_set = LibriDataset(val_X, val_y)\n",
    "\n",
    "# remove raw feature to save memory\n",
    "del train_X, train_y, val_X, val_y\n",
    "gc.collect()\n",
    "\n",
    "# get dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07163241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:27:06.297503Z",
     "iopub.status.busy": "2024-09-10T01:27:06.296472Z",
     "iopub.status.idle": "2024-09-10T01:27:06.360220Z",
     "shell.execute_reply": "2024-09-10T01:27:06.359393Z"
    },
    "id": "CfRUEgC0GxUV",
    "outputId": "f9804711-72b1-4717-896b-821a300cfe87",
    "papermill": {
     "duration": 0.107806,
     "end_time": "2024-09-10T01:27:06.362292",
     "exception": false,
     "start_time": "2024-09-10T01:27:06.254486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eac180e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:27:06.446270Z",
     "iopub.status.busy": "2024-09-10T01:27:06.445633Z",
     "iopub.status.idle": "2024-09-10T01:27:06.451123Z",
     "shell.execute_reply": "2024-09-10T01:27:06.450163Z"
    },
    "id": "88xPiUnm0tAd",
    "papermill": {
     "duration": 0.049761,
     "end_time": "2024-09-10T01:27:06.453215",
     "exception": false,
     "start_time": "2024-09-10T01:27:06.403454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#fix seed\n",
    "def same_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b236bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:27:06.536951Z",
     "iopub.status.busy": "2024-09-10T01:27:06.536406Z",
     "iopub.status.idle": "2024-09-10T01:27:07.945398Z",
     "shell.execute_reply": "2024-09-10T01:27:07.944592Z"
    },
    "id": "QTp3ZXg1yO9Y",
    "papermill": {
     "duration": 1.453539,
     "end_time": "2024-09-10T01:27:07.947758",
     "exception": false,
     "start_time": "2024-09-10T01:27:06.494219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fix random seed\n",
    "same_seeds(seed)\n",
    "\n",
    "# create model, define a loss function, and optimizer\n",
    "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=7, T_mult=2, eta_min=1e-5) # 0.732"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790da47b",
   "metadata": {
    "id": "pwWH1KIqzxEr",
    "papermill": {
     "duration": 0.040656,
     "end_time": "2024-09-10T01:27:08.029567",
     "exception": false,
     "start_time": "2024-09-10T01:27:07.988911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c0afbf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:27:08.113327Z",
     "iopub.status.busy": "2024-09-10T01:27:08.112824Z",
     "iopub.status.idle": "2024-09-10T01:53:47.539936Z",
     "shell.execute_reply": "2024-09-10T01:53:47.538823Z"
    },
    "id": "CdMWsBs7zzNs",
    "outputId": "17922ad2-a319-4253-8783-3e4939d0a7cf",
    "papermill": {
     "duration": 1599.47177,
     "end_time": "2024-09-10T01:53:47.541994",
     "exception": false,
     "start_time": "2024-09-10T01:27:08.070224",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:52<00:00, 94.18it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 167.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/030] Train Acc: 0.586099 Loss: 1.346225 | Val Acc: 0.658911 loss: 1.087648\n",
      "saving model with acc 0.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.13it/s] \n",
      "100%|██████████| 256/256 [00:01<00:00, 155.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[002/030] Train Acc: 0.636403 Loss: 1.155155 | Val Acc: 0.682446 loss: 1.008712\n",
      "saving model with acc 0.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.07it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 157.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[003/030] Train Acc: 0.655484 Loss: 1.086660 | Val Acc: 0.691744 loss: 0.971707\n",
      "saving model with acc 0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.00it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 157.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[004/030] Train Acc: 0.669362 Loss: 1.038188 | Val Acc: 0.705035 loss: 0.928933\n",
      "saving model with acc 0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.08it/s] \n",
      "100%|██████████| 256/256 [00:01<00:00, 150.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[005/030] Train Acc: 0.679584 Loss: 1.001635 | Val Acc: 0.710500 loss: 0.909378\n",
      "saving model with acc 0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 94.79it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 153.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[006/030] Train Acc: 0.686920 Loss: 0.974468 | Val Acc: 0.715775 loss: 0.894828\n",
      "saving model with acc 0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 94.96it/s] \n",
      "100%|██████████| 256/256 [00:01<00:00, 156.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[007/030] Train Acc: 0.691978 Loss: 0.958360 | Val Acc: 0.717432 loss: 0.889292\n",
      "saving model with acc 0.717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 94.97it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 156.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[008/030] Train Acc: 0.679307 Loss: 1.000523 | Val Acc: 0.710165 loss: 0.911812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.14it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 154.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[009/030] Train Acc: 0.684651 Loss: 0.981120 | Val Acc: 0.713584 loss: 0.903451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 94.97it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 154.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[010/030] Train Acc: 0.690839 Loss: 0.958479 | Val Acc: 0.718226 loss: 0.888295\n",
      "saving model with acc 0.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.28it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 156.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[011/030] Train Acc: 0.696509 Loss: 0.938520 | Val Acc: 0.721623 loss: 0.875826\n",
      "saving model with acc 0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 94.45it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 149.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[012/030] Train Acc: 0.701947 Loss: 0.918760 | Val Acc: 0.723134 loss: 0.870925\n",
      "saving model with acc 0.723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 94.44it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 155.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[013/030] Train Acc: 0.707497 Loss: 0.899636 | Val Acc: 0.726272 loss: 0.862524\n",
      "saving model with acc 0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 94.70it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 154.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[014/030] Train Acc: 0.712337 Loss: 0.881494 | Val Acc: 0.727425 loss: 0.857966\n",
      "saving model with acc 0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.29it/s] \n",
      "100%|██████████| 256/256 [00:01<00:00, 157.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[015/030] Train Acc: 0.716863 Loss: 0.866074 | Val Acc: 0.730570 loss: 0.851183\n",
      "saving model with acc 0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.21it/s] \n",
      "100%|██████████| 256/256 [00:01<00:00, 155.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[016/030] Train Acc: 0.721066 Loss: 0.850603 | Val Acc: 0.732852 loss: 0.845445\n",
      "saving model with acc 0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.49it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 158.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[017/030] Train Acc: 0.725443 Loss: 0.836418 | Val Acc: 0.733830 loss: 0.840643\n",
      "saving model with acc 0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.46it/s] \n",
      "100%|██████████| 256/256 [00:01<00:00, 153.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[018/030] Train Acc: 0.728410 Loss: 0.825765 | Val Acc: 0.735456 loss: 0.836307\n",
      "saving model with acc 0.735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.64it/s] \n",
      "100%|██████████| 256/256 [00:01<00:00, 155.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[019/030] Train Acc: 0.731333 Loss: 0.815879 | Val Acc: 0.735188 loss: 0.835393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.49it/s] \n",
      "100%|██████████| 256/256 [00:01<00:00, 155.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[020/030] Train Acc: 0.732927 Loss: 0.809497 | Val Acc: 0.735936 loss: 0.833839\n",
      "saving model with acc 0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.30it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 158.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[021/030] Train Acc: 0.734645 Loss: 0.805334 | Val Acc: 0.737570 loss: 0.831850\n",
      "saving model with acc 0.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 96.01it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 157.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[022/030] Train Acc: 0.717843 Loss: 0.859397 | Val Acc: 0.727012 loss: 0.860743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.34it/s] \n",
      "100%|██████████| 256/256 [00:01<00:00, 158.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[023/030] Train Acc: 0.717909 Loss: 0.858926 | Val Acc: 0.728875 loss: 0.857302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.22it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 151.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[024/030] Train Acc: 0.720075 Loss: 0.852013 | Val Acc: 0.729677 loss: 0.857357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.24it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 157.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[025/030] Train Acc: 0.722626 Loss: 0.842501 | Val Acc: 0.730929 loss: 0.853180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.29it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 156.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[026/030] Train Acc: 0.724867 Loss: 0.833870 | Val Acc: 0.731265 loss: 0.854246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 95.04it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 154.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[027/030] Train Acc: 0.727225 Loss: 0.824965 | Val Acc: 0.731020 loss: 0.855194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 94.88it/s]\n",
      "100%|██████████| 256/256 [00:01<00:00, 153.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[028/030] Train Acc: 0.729739 Loss: 0.816026 | Val Acc: 0.731753 loss: 0.852994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 94.82it/s] \n",
      "100%|██████████| 256/256 [00:01<00:00, 153.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[029/030] Train Acc: 0.732369 Loss: 0.807084 | Val Acc: 0.732165 loss: 0.850573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4909/4909 [00:51<00:00, 94.80it/s] \n",
      "100%|██████████| 256/256 [00:01<00:00, 152.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[030/030] Train Acc: 0.735050 Loss: 0.797526 | Val Acc: 0.733349 loss: 0.849326\n",
      "1599.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epoch):\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    # training\n",
    "    model.train() # set the model to training mode\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        features, labels = batch\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() \n",
    "        outputs = model(features) \n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() \n",
    "        optimizer.step()        \n",
    "        \n",
    "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
    "        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # validation\n",
    "    if len(val_set) > 0:\n",
    "        model.eval() # set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(tqdm(val_loader)):\n",
    "                features, labels = batch\n",
    "                features = features.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(features)\n",
    "                \n",
    "                loss = criterion(outputs, labels) \n",
    "                \n",
    "                _, val_pred = torch.max(outputs, 1) \n",
    "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
    "                val_loss += loss.item()\n",
    "\n",
    "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
    "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
    "            ))\n",
    "\n",
    "            # if the model improves, save a checkpoint at this epoch\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n",
    "    else:\n",
    "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
    "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
    "        ))\n",
    "        \n",
    "    scheduler.step()\n",
    "print(f'{time.time() - tic:.2f} sec')\n",
    "\n",
    "# if not validating, save the last epoch\n",
    "if len(val_set) == 0:\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print('saving model at last epoch')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbe0ac9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:53:50.025060Z",
     "iopub.status.busy": "2024-09-10T01:53:50.024261Z",
     "iopub.status.idle": "2024-09-10T01:53:50.153268Z",
     "shell.execute_reply": "2024-09-10T01:53:50.152380Z"
    },
    "id": "ab33MxosWLmG",
    "outputId": "911e8c9b-fc0f-4591-b0f6-311a1231c5e2",
    "papermill": {
     "duration": 1.389589,
     "end_time": "2024-09-10T01:53:50.155382",
     "exception": false,
     "start_time": "2024-09-10T01:53:48.765793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_loader, val_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c2d971",
   "metadata": {
    "id": "1Hi7jTn3PX-m",
    "papermill": {
     "duration": 1.229864,
     "end_time": "2024-09-10T01:53:52.570718",
     "exception": false,
     "start_time": "2024-09-10T01:53:51.340854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing\n",
    "Create a testing dataset, and load model from the saved checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39d409b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:53:54.998352Z",
     "iopub.status.busy": "2024-09-10T01:53:54.997495Z",
     "iopub.status.idle": "2024-09-10T01:54:06.367196Z",
     "shell.execute_reply": "2024-09-10T01:54:06.366077Z"
    },
    "id": "VOG1Ou0PGrhc",
    "outputId": "abaaa25b-a93c-49b0-d228-9eca1e2ab2e0",
    "papermill": {
     "duration": 12.561153,
     "end_time": "2024-09-10T01:54:06.369520",
     "exception": false,
     "start_time": "2024-09-10T01:53:53.808367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] - # phone classes: 41, number of utterances for test: 1078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_23/2993276178.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  feat = torch.load(path)\n",
      "1078it [00:11, 95.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test set\n",
      "torch.Size([646268, 585])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "test_X = preprocess_data(split='test', feat_dir='/kaggle/input/libriphone/libriphone/feat', phone_path='/kaggle/input/libriphone/libriphone', concat_nframes=concat_nframes)\n",
    "test_set = LibriDataset(test_X, None)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ce843d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:54:08.800334Z",
     "iopub.status.busy": "2024-09-10T01:54:08.799916Z",
     "iopub.status.idle": "2024-09-10T01:54:08.895841Z",
     "shell.execute_reply": "2024-09-10T01:54:08.894674Z"
    },
    "id": "ay0Fu8Ovkdad",
    "outputId": "e5b20aa7-4d8b-43a9-e068-f5c89706a360",
    "papermill": {
     "duration": 1.284596,
     "end_time": "2024-09-10T01:54:08.897815",
     "exception": false,
     "start_time": "2024-09-10T01:54:07.613219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/3352857437.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce33b2",
   "metadata": {
    "id": "zp-DV1p4r7Nz",
    "papermill": {
     "duration": 1.244568,
     "end_time": "2024-09-10T01:54:11.430878",
     "exception": false,
     "start_time": "2024-09-10T01:54:10.186310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Make prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9af819d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:54:13.837183Z",
     "iopub.status.busy": "2024-09-10T01:54:13.836402Z",
     "iopub.status.idle": "2024-09-10T01:54:19.388143Z",
     "shell.execute_reply": "2024-09-10T01:54:19.387149Z"
    },
    "id": "84HU5GGjPqR0",
    "outputId": "cebd6694-8f74-44ff-f922-96ca4385acb8",
    "papermill": {
     "duration": 6.779002,
     "end_time": "2024-09-10T01:54:19.390600",
     "exception": false,
     "start_time": "2024-09-10T01:54:12.611598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1263/1263 [00:05<00:00, 227.89it/s]\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0.0\n",
    "test_lengths = 0\n",
    "pred = np.array([], dtype=np.int32)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(test_loader)):\n",
    "        features = batch\n",
    "        features = features.to(device)\n",
    "\n",
    "        outputs = model(features)\n",
    "\n",
    "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
    "        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55dacaa",
   "metadata": {
    "id": "wyZqy40Prz0v",
    "papermill": {
     "duration": 1.193904,
     "end_time": "2024-09-10T01:54:21.827376",
     "exception": false,
     "start_time": "2024-09-10T01:54:20.633472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Write prediction to a CSV file.\n",
    "\n",
    "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5f2ad58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T01:54:24.308624Z",
     "iopub.status.busy": "2024-09-10T01:54:24.307699Z",
     "iopub.status.idle": "2024-09-10T01:54:25.123284Z",
     "shell.execute_reply": "2024-09-10T01:54:25.122245Z"
    },
    "id": "GuljYSPHcZir",
    "papermill": {
     "duration": 2.062657,
     "end_time": "2024-09-10T01:54:25.125675",
     "exception": false,
     "start_time": "2024-09-10T01:54:23.063018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/working/prediction.csv', 'w') as f:\n",
    "    f.write('Id,Class\\n')\n",
    "    for i, y in enumerate(pred):\n",
    "        f.write('{},{}\\n'.format(i, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5608e24",
   "metadata": {
    "papermill": {
     "duration": 1.236616,
     "end_time": "2024-09-10T01:54:27.572605",
     "exception": false,
     "start_time": "2024-09-10T01:54:26.335989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML2022Spring - HW2.ipynb",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5666188,
     "sourceId": 9348233,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1701.466265,
   "end_time": "2024-09-10T01:54:30.528068",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-10T01:26:09.061803",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
